---
title: 1 – מבוא ותורת המידע
author: nirgn
layout: post
summary: ""
category: Information Theory
---
בכל סמסטר בו אני לומד איזשהו קורס, כחלק מהלימוד עצמו אני קורא ספרים, פותר תרגילים, מכין סיכומים וכד’. ולאחרונה התחלתי ללמוד כריית מידע (Data Mining), אז כמו בחלק מהקורסים הקודמים, החלטתי לכתוב סדרת פוסטים המהווה יומן מסע ותכיל את הסיכומים של חומרי הלימוד כפי שאני לומד ומכין אותם. הספר עליו אני מתבסס הוא [Data Mining Concepts and Techniques (מהדורה שלישית)](http://www.amazon.com/Data-Mining-Concepts-Techniques-Management/dp/0123814790) והוא זמין גם כ[קובץ PDF](http://www.cse.hcmut.edu.vn/~chauvtn/data_mining/Texts/%5B1%5D%20Data%20Mining%20-%20Concepts%20and%20Techniques%20%283rd%20Ed%29.pdf).

בפוסט זה נדבר על:
1. למה לכרות מידע?
2. מהי כריית מידע?
3. מודלים ואלגוריתמים
4. מחסן נתונים מול מסד נתונים
5. תורת האניפורמציה
6. תקשורת
7. הגישות השונות לכריית מידע

<!--more-->

&nbsp;

### 1. למה לכרות מידע?
אנחנו חיים בעולם עם כמויות עצומות של מידע הנאסף מידי יום, וניתוח של המידע הוא פעולה חשובה. נראה כיצד פעולת כריית המידע עונה על צורך זה בעזרת סיפוק כלים לחשיפת הידע מהמידע, ונראה כיצד פעולת כריית מידע  ניראת אבולוציה טבעית לתוצאה של מידע טכנולוגי.

“אנחנו חיים בעידן המידע” היא אמרה פופולרית, אך האמת היא שאנחנו חיים בעידן הנתונים. טאראה בייטים ואפילו פטאבייטים של מידע נשפכים לרשתות המחשבים שלנו, לאינטרנט (WWW), ומרכזי אחסון נתונים שונים בכל יום מהעסקים השונים, מהחברה באופן כללי, מתחום המדע, ההנדסה, הרפואה, ובקיצור כמעט מכל אספקט של חיי היום יום שלנו. הפיצוץ האדיר הקיים בשנים האחרונות של נתונים נובע ממהפכת המחשוב שהחברה שלנו עוברת והפיתוח המהיר של כלים חזקים לאיסוף ואחסון נתונים.

מכאן נולד הצורך לכלים חזקים ורב תכליתיים שבאופן אוטומטי יחשפו מידע יקר מהררי המידע הזמינים, ואף יהפכו אותו לידע מאורגן. הצורך הזה הוביל להולדת התחום הנקרא כריית מידע. תחום צעיר, דינמי, ומבטיח המתיימר להביא אותנו מעידן הנתונים אל עידן המידע.

דוגמה: כריית מידע הופכת אוסף גדול של נתונים לידע. מנוע חיפוש (דוגמת Google) מקבל מאות מליוני שאילתות בכל יום, כל שאילתה מתארת את הצורך / המידע שהמשתמש מבקש. באופן מעניין נמצאו תבניות בשאילתות החיפוש של המשתמשים. לדוגמה, הצליחה גוגל למצוא קשר ישיר בין מס’ האנשים שחיפשו על מידע הקשור לשפעת ומספר האנשים בפועל שהיה להם סימפטומים של שפעת.  בעזרת איסוף המידע, גוגל מצליחה להעריך פעילות של שפעת באזור מסוים עד לשבועיים מהר יותר (לפני) מערכות מסורתיות.

&nbsp;

### 2. מהי כריית מידע?
כריית מידע יכולה להיות מוגדרת במגוון דרכים שונות, ולמרות שאולי לא מייצגת כהלכה את המשמעות, כרייה היא תהליך של מציאת דבר מה יקר, קטן, ממידה רבה של חומר גלם כלשהו. מושג פופולרי נוסף, ואולי אף מדויק יותר הוא Knowledge Discovery in Databases (חשיפת / גילוי מידע במסדי נתונים או KDD). המושג מתייחס לתהליך הלא טריוואלי של זיהוי דפוסי מידע תקפים / שעשויים להיות שימושיים / מובנים / חדשים.

כריית מידה יכולה להיות מיושמת לכל סוג של נתונים. הצורה הבסיסית ביותר של יישום כריית המידע היא לנתונים במסדי נתונים, במחסני נתונים, ונתוני עסקאות (טרנזקציות). אך כריית מידע יכולה להיות מיושמת גם על צורות אחרות של נתונים, כמו זרמי נתונים, נתוני רשת, נתוני גרף, נתונים מרחביים, נתוני טקסט, נתוני מולטימדיה, וגם ה WWW.

**תחומי יישום KDD:**

* **CRM** ([ניהול קשרי לקוחות](http://en.wikipedia.org/wiki/Customer_relationship_management)) – תחום העוסק בשירות לקוחות, הבנה וניתוח צרכיהם. המערכות מתיימרות לזהות את המאפיינים של הלקוח, דפוסי הצריכה, העדפות, מידת שביעות רצונו, ואף חיזוי סיכויי הנטישה של הלקוח.
* **פיננסים** – זיהוי זיופים ע”י הרגלי צריכה בכרטיס אשראי, דירוג קרדיט בנקאי, אישור הלוואות והתאמת ריביות, חיזוי מניות ושערי מטבעות, וכד’.
* **שיווק ומסחר** – פניות באמצעות דואר או אימייל לרכישת מוצרים, חיתוך קהלי יעד, חיזוי המידע שבו המשתמש מעוניין, וכ’ו.
* **פריצות למערכות מחשבים** – זיהוי פריצה ע”י הרגילה שימוש וכד’ (תחום שעדיין בחיתולים יחסית).
* **רפואה** – שיפור הבחנות הרפואיות, זיהוי טיפולים אופטימליים לסוג מסוים של חולים, וכ’ו.
* **ביטחון** – זיהוי קשרים לארגונים או מבוקשים מסויימים, הפקת מידע לשימוש ארגוני ביון וכד’.

**תהליך חשיפת המידע הוא תהליך איטרטיבי של הצעדים הבאים:**

* **מטרות** – זיהוי מטרות התהליך, מדוע אנחנו רוצים לבצע בכלל את פעולת כריית המידע (להפעיל אלגוריתמים לכריית מידע על הנתונים).
* **בחירת נתונים** – בחירת הנתונים ממסד נתונים קיים, יצירת הנתונים (במידת הצורך) ע”י בחירת מדגם, וכ’ו
* **ניקוי המידע** – בדרך כלל כשמדובר על נתונים אמיתיים יש צורך לנקות אותם, ז”א כוליים מידע לא מדויק, חלק מהנתונים שגויים, לא רלוונטים. במצב כזה נשאלת השאלה כיצד מזהים נתונים שגויים? וכיצד מתמודדים במצב שחסרים לנו נתונים?
* **שילוב נתונים** – שילוב כל כמה מקומות מידע למחסן נתונים אחד (צעד זה אינו הכרחי).
בחירת ושינוי הנתונים – בחירת הנתונים / ערכים הרלוונטים ביותר, ולפעמים גם הגדרת משתנים חדשים (ע”י חישוב מהנתונים הקיימים).
* **כריית מידע** – נפנה לאלגוריתמים לכריית מידע ונריץ אותם על סט הנתונים שבחרנו. במידה וקיים צורך להתאמת הנתונים לכרייה על פי האלגוריתמים שבחרנו.
* **הערכת דפוסים / תבניות** – זיהוי התבניות, יישום טכניקות הצגת המידע (ויזואליזציה) למשתמשים, שחזור מטה-נתונים ([Metadata](http://en.wikipedia.org/wiki/Metadata)) כדי להבין את המשמעות של התבניות והדפוסים שנחשפו, הפקת התבניות בעזרת שיטות סטטיסטיות כמו מובהקות סטטיסטית, מעוניינות, חשיבות, רלוונטיות, אפשרות פעולה, וכ’ו.
לעיתים קרובות, לאחר הערכת התבניות נגלה שהמטרה לא הושגה ואנו לא מרוצים מהתוצאות, לכן יש צורך לחזור על חלק מהשלבים. לדוגמה לחזור על שלבי הכנת הנתונים (1-4) ולהכין אותם בצורה שונה, לחזור על שלב 5 ולבחור סט נתונים קצת שונה, הרצת אלגוריתם אחר או עוד אחד, או שינוי הפרמטרים שלו (שלב 6), ועוד.

&nbsp;

### 3. מודלים ואלגוריתמים
**המודלים בתחום כריית המידע נחלקים ל-3 קטגוריות:**

* **מודלי קופסא לבנה** – מודלים מוכרים בהם אנו לא זקוקים לנתונים חדשים על מנת ללמוד את המודלים האלו. המודלים ידועים והתגלו בעבר, וכל שאנו עושים (באמצעות הנתונים) הוא לאושש את אותם מודלים (לדוגמה מודלים המאששים חוקים פיזקליים, המודלים מגיעים מתוך נתונים שהגיעו מעריכת ניסויי מעבדה).
* **מודלי קופסא אפורה** – אנו כן יודעים את הצורה הכללית של המודל (לדוגמה מודל לרגרסיה לינארית, Y = ax + b). אך אנחנו לא בטוחים לגבי הפרמטרים השונים של המודל. גם מודלים אלה יחסית קלים לחישוב, ולכן רוב הזמן כשנדבר על אלגוריתמים לכריית מידע נתכוון להפקה של המודלים השחורים.
* **מודלי קופסא שחורה** – מודלים מורכבים לדוגמה מודל של רשת נויירונים (ANN, ראשי תיבות: [Artificial Neural Network](http://en.wikipedia.org/wiki/Artificial_neural_network)). מודלים שקשה להבינם, מורכבים מעשרות או מאות אלמנטים שונים.


חשוב לציין כי תחום כריית המידע צמח מתחומים קיימים כמו זיהוי תבניות (הכולל זיהוי תווים, אובייקטים, פנים וכד’), Machine Learning (למידה מניסיון, וההנחה שככל שנצבור יותר ניסיון, יהיו יותר נתונים, נפיק יותר ידע לגבי התהליך הנחקר), סטטיסטיקה והסתברות (למידה מידע לא מושלם, רועש), אלגוריתמים ותאוריות חישוב מורכבות, תורת הבקרה (איזון של התהליך מתוך פידבק חוזר), תאוריית האינפורמציה, ועוד.

בכנס ICDM שנערך בדצמבר 2006 (אחד מהכנסים הראשיים לכריית מידע), נערכה הצעה לאלגוריתמים השימושיים ביותר בתחום. ולהלן הטבלה למטה (בצירוף הבעיה הנפתרת ע”י כל אחד מהאלגוריתמים):

| סוג הבעיה שהאלגוריתם פותר | Algorithm | Rank |
|:---:|:---:|:---:|
| עצי החלטה | C4.5 | 1 |
| ניתוח אשכולות | K-Means | 2 |
| סיווג ורגרסיה | SVM | 3 |
| חוקי הקשר | Apriori | 4 |
| ניתוח אשכולות | EM | 5 |
| כרייה באינטרנט | PageRank | 6 |
| Ensemble learning | AdaBoost | 7 |
| למידה מבוססת תצפיות | Knn | 8 |
| למידה בייסיאנית | Naive Bayes | 9 |
| עצי החלטה | CART | 10 |

 &nbsp;

ישנן כמה שיטות לכריית מידע, אחת משיטות הסיווג המצויות בשימוש היא עץ החלטה. כדי לקבל מושג קל, נציג עץ החלטה כזה ונסביר את המונחים הקשורים אליו. עץ הוא מבנה אבסטרקטי המתאר היררכיה בין אובייקטים. בעץ ישנם קודקודים (צמתים) עם קשר אב-בן, דוגמה לעץ כזה היא אילן יוחסין. קיימים אלגוריתמים שונים לבניית עצי החלטה (נדבר עליהם בעתיד). אך על עץ החלטה יכיל את המבנה הבא:

* שורש – קודקוד (צומת) ללא אב. בדוגמה משמאל זהו A.
* בן – קודקוד G הוא בן של קודקוד C אם יש קשת מ C ל G.
* אב – קודקוד C הוא אב של קודקוד G, אם יש קשת מ C ל G.
* עלה – קודקוד ללא בנים. לדוגמה G.
* קודקוד פנימי – קודקוד שאינו עלה ושהוא אינו שורש, כלומר יש לו אב ולפחות בן אחד. לדוגמה C, F, B.
* צאצא – קודקוד I הוא צאצא של B, אם יש מסלול אבות-בנים מ B ל I.
* אב קדמון – קודקוד B הוא אב קדמון של J, אם יש מסלול של אבות-בנים מ B ל J.
* תת עץ – תת עץ המורש מ B, זהו עץ ש B הוא שורש שלו, ומכיל את כל הקודקודים ש B הוא אב קדמון שלהם ואת הקשתות ביניהם בעץ המקורי.

את העץ נקבל כתוצאה משימוש באלגוריתמים לבניית עצי החלטה (לא נציין אותם כרגע). כל קודקוד בעץ הוא שאלה שאנו צריכים לענות עליה ולפיה ללכת לבן המתאים, וכל עלה הוא תוצאה אפשרית (חיזוי).

ישנם מודלים נוספים של כריית מידע כמו אשכול ([Cluster](http://en.wikipedia.org/wiki/Cluster_analysis)). אשכול הוא קבוצה של רשומות בעלות מאפיינים דומים. ניתוח אשכולות הוא פילוח רשומות בבסיס נתונים לאשכולות, כך שבכל אשכול נמצאים רשומות בעלות מאפיינים דומים. לדוגמה, ניתן לפלח את הסטודנטים לפי ההישגים שלהם (מצטיינים, טובים, בינוניים, וחלשים) באו”פ. דוגמה נוספת יכולה להיות פילוח הסטודנטים לפי אזורי מגורים. ישנו גם מודל רגרסיה ([Regression](http://en.wikipedia.org/wiki/Regression_analysis)). שהיא שיטה סטטיסטית המשמשת לבדיקה ולניבוי של קשרים בין שני משתנים (או יותר) (שיטה זו מצויה בשימוש נרחב במחקרים כמותיים בתחומי הדע השונים. הרגרסיה הפשוטה ביותר היא רגרסיה לינארית עם שני משתנים: משתנה מסביר ומשתנה מוסבר).

 &nbsp;

### 4. מחסן נתונים מול מסד נתונים
מערכת מסד נתונים (נקראת גם [Database Management System או DBMS](http://en.wikipedia.org/wiki/Database)) מכילה אוסף של נתונים הקשורים זה לזה, הידועים גם כ”מסד נתונים”, וסט של כלים / תוכנות לניהול וגישה לנתונים. התוכנות מספקות מנגנונים להגדרת מבנה ואחסון מסד הנתונים, לציון וניהול בו זמני, שיתוף או גישה מבוזרת לנתונים, והבטחת עקביות וביטחון של הנתונים המאוחסנים על אף קריסות מערכת או ניסיונות גישה לא מורשים. DBMS כזה נקרא גם בסיס נתונים תפעולי, ומשמש לביצוע ותיעוד הפעילות השוטפת של הארגון. העיבוד בו מכונה עיבוד תפעולי מקוון או OLTP (ראשי תיבות: Online Transactional Processing).

לעומתו, קיים סוג נוסף של בסיס נתונים המשמש לעיבוד ולניתוח נתונים שהצטברו במערכות קיימות, ובדרך כלל מדובר במערכות תפעוליות. בבסיסי הנתונים האלו מתבצעת אינטגרציה של נתונים ממערכות שונות (תוך כדי טיפול בשמות שונים של אותם משתנים, יחידות מידנה שונות, מפתחות שונים וכד’). נתונים אלו מאוחסנים בצורה סיכומית ובחתכים המקלים על תהליכי העיבוד והניתוח, והנתונים יציבים יחסית ומעודנים בתידורת שנקבעת מראש (הנתונים נשמרים לפרקי זמן ארוכים יותר מב DBMS, ואינם מתעדכנים באותה תדירות, ובטח שלא בזמן אמת, כמו ה DBMS). בסיס נתונים זה נקרא מחסן נתונים או DW (ראשי תיבות: Data Warehouse), והעיבוד המבוצע ע”י DBA, כדוגמת עיבוד שאילתות והפקת דוחות, מכונה עיבוד אנליטי מקוון או OLAP (ראשי תיבות: Online Analytical Processing).

[bill inmon](http://en.wikipedia.org/wiki/Bill_Inmon) (אחד מהאבות של התחום) מגדיר את מחסן הנתונים כמאגר נתונים המוכוון לנושא מסויים, ומשלב נתונים ממוקורות שונים. הנתונים הינם תלויי זמן ובלתי נדיפים (אינם ניתנים למחיקה). המטרה של מחסן נתונים שכזה הוא לתמוך בתהליך קבלת ההחלטות של ההנהלה. ולרוב מקושר לנושא מסויים (שיווק, רכישה, ייצור, בקרת איכות וכ’ו).

  &nbsp;

**קוביית מידע**

מודל הנתונים עבור OLAP הוא מודל רב מימדי. כלומר, מסתכלים על המידע מנקודת המבט של מדד כמותי אחד שמעניין את המשתמש לפי ממדים – חתכים שונים. במחסן הנתונים עשויים להיות מספר מדדים שמעניינים את המשתמש, ולכל אחד מהם כמה מדדים. עיבוד נתוני מחסן הנתונים מתבצע על ידי משתמש הקצה באמצעות כלי OLAP, כשהנפוץ בינהם הוא קוביית מידע ([Data Cube](http://en.wikipedia.org/wiki/OLAP_cube)). בצד שמאל ישנה דוגמה לקוביית מידע בה אנו מתארים את נפחי המכירות בחברה Sony כפונקציה של מוצרים (טלוויזיות, מחשבים וכד’), רבעונים, וארצות (ארה”ב, קנדה, ומקסיקו). ממדי הנתונים מוגדרים באופן הבא: מיקום, מכירה, זמן.

> אציין כי ניתן ליצור קוביות מידע בעלות יותר מ-3 ממדים, אך כמובן שלא נוכל לתאר אותן באופן וויזואלי כמו שאנו ממחישים בצד שמאל קובייה בעלת שלושה מימדים.

ניתן לבצע מגוון פעולות על הנתונים שבמחסן המידע. נראה את הפעולות, ונייצג אותן באמצעות קוביית המידע:

* **Roll up (או Drill up)** – פעולה המיועדת לסיכום הנתונים, ז”א סיכום הנתונים ברמה גבוהה יותר (לדוגמה: במקום ברבעונים, בשנים).
* **Roll down (או Drill down)*** – פעולה הפוכה המיועדת לעבור מרמת סיכום גבוהה לרמת סיכום נמוכה (לדוגמה: מרמת רבעונים לרמת חודשים, או מרמה של קטגוריות מוצרים לדגמים ספציפיים).
* **Slice and Dice** – פעולה בה אנו מחפשים שילוב בין ערכים של שני מימדים שונים. ב Slice אנו מגבילים את עצמנו לערכים של מימד אחד, וב Dice אנו משלבים לפחות 2 מימדים.
* **Pivot (או Rotate)** – בפעולה זו אנו רק משנים את ההצגה של הנתונים (מסובבים את הטבלה ב-90 מעלות, על מנת להקהל על המשתמש).
* **Drill Across** – כאשר אנו עוברים מטבלת עובדות אחת לטבלת עובדות נוספת (נרחיב על טבלת עובדות בהמשך).
* **Drill Through** – כאשר אנו מגיעים לרמה הנמוכה ביותר של הנתונים הגולמיים.

  &nbsp;

### 5. תורת האינפורמציה
[קלוד שאנון](http://en.wikipedia.org/wiki/Claude_Shannon) אבי תורת האינפורמציה פרסם את המאמר “The mathematical theory of communication” ב-1949 שהיווה את היסוד לתורה זו, ובו הנחיל את המושגים הבסיסיים שאנו משתמשים בהם עד היום. תורת האינפורמציה פותחה במטרה לטפל בהעברת מידע במערכות תקשורת. המרכיבים העיקריים שלה הם קידוד מקור וקידוד ערוץ עבור משתנים מקריים בדידים.

העברה יעילה של מידע דיגיטלי דרך ערוץ רועש ומבובש מבוצעת ב-2 שלבים עיקריים: _1. קידוד מקור_ – נדחס את המידע הגולמי המיועד להעברה ע”י ניצול התכונות הסטטיסטיות שקיימות בו, ונקודד אותו. _2. קידוד ערוץ_ – נוסיף למידע המועבר אינפרמציה יתירה, כך שמקבל המידע בצד השני של הערוץ הרועש יוכל לנקותו מרעשים.

תורת האינפורמציה מספקת לנו מסגרת פורמלית כדי למצוא ולהעריך תבניות (שזהו המטרה העקרית שלנו בכריית מידע, למצוא תבניות ובעזרת קריטריונים אובייקטים להעריך אותם כדי למצוא את התבניות האינפורמטיביות ביותר, ולהעריך את מידת האינפורמטיביות שלהם ביחס לתבניות אחרות שמצאנו / שנמצאו בעבר). באמצעות תורת האינפורמציה ניתן להגדיר מדדים לשימושיות ולנצילות של טכניקות ומודלים שונים בכריית מידע. לדוגמה, בעת בניית עץ החלטה (נושא שנרחיב עליו בהמשך) נסתייע במדד האנטרופיה לקביעה מהי התכונה המפצלת בעץ ההחלטה.

**מדידת חוסר ודאות**

חוסר ודאות זה מושג הקיים בכל עסק. המטרה של כריית המידע היא לספק מידע שיפחית את חוסר הוודאות הקיים בקבלת ההחלטות בארגון. לדוגמה אם התבצעה פעולה בכרטיס אשראי, כיצד חברת האשראי יכולה לקבוע האם הפעולה חוקית או לא? זהו מצב של חוסר ודאות. ונשאלת השאלה כיצד ניתן למדוד חוסר ודאות? האם יש איזשהו מדד שמבחין בין אירועים עם אי ודאות גבוהה לאי וודאות נמוכה? נתחיל בכך שאם אנו יכולים לחזות את התוצאה בודאות של 100% ברור לנו שחוסר הודאות שווה ל-0. בנוסף, אי הודאות עולה כאשר מספר האופציות האפשריות עולות. ולבסוף, לאותו מס’ תוצאות אפשריות, אי הודאות היא מקסימלית אם קיים אותו סיכוי (אותה הסתברות) לכל תוצאה אפשרית.

**אנטרופיה**

מדד האנטרופיה עוזר לנו להעריך את אי הודאות של משתנה מקרי כלשהו (X) (משתמשים במושג זה גם בפיזיקה, בתרמודינמיקה). האנטרופיה נחשבת מדד לאי ודאות על קבוצת מצבים אפשריים, והיא אינה תלויה בערכים שהמשתנה מקבל אלא רק בפונקצית ההתפלגות שלו. _האנטרופיה של משתנה מקרי בדיד_ מקבלת ערך מינימלי יחיד כאשר אי הודאות מינימלית, וערך מקסימלי עבור אי ודאות מקסימלית. _אנטרופיה של התפלגות כלשהי_ מהווה מדד למרחק סטטיסטי שבין התפלגות נתונה לבין התפלגות אחידה. יש לציין כי אנטרופיה היא בעלת ערכים חיובים בלבד ונמדדת ביחידות nats (כאשר משתמשים בבסיס הטבעי של הלוגריתם) או bits (כאשר משתמשים בבסיס 2).

האנטרופיה מוגדרת כ- `(H(X) = Σ-p(x)logp(x`. נציין כמה תכונות של הנוסחה:

* המינוס נמצא שם כדי לספק תוצאה חיובית (הסתברות היא תמיד בין 1-0 ולוגריתם של מס’ בטווח הזה יתן מס’ 0 או שלילי).
* התוצאה של האנטרופיה, (H(X, תיהיה שווה ל-0 אם”ם (אם ורק אם) האירוע וודאי (אירוע בעל תוצאה אפשרית אחת בלבד).
* הערך המקסימלי שאנטרופיה יכולה להגיע אליו שווה לוגריתם של מס’ התוצאות האפשריות.
* אם לכל התוצאות יש את אותה הסתברות, האנטרופיה הוא פונ’ מונוטונית עולה של מס’ התוצאות.

בדוגמה לחישוב אנטרופיה בתמונה משמאל אנו מחשבים את האנטרופיה לבדיקה רפואית, אנו רואים בטבלה הראשונה שלנבדק אחד יצאה תוצאה שלילית ובכל זאת חלה, ל-3 יצאה תוצאה שלילית בבדיקה ואכן אינם חלו, ל-4 יצאה תוצאה חיובית ואכן חלו, ול-2 יצאה תוצאה חיובית אך לא חלו. בטבלה השניה אנו מחשבים את האנטרופיה של הבדיקה, ז”א 6 חלו ו-4 לא, לכן האנטרופיה של הבדיקה היא 0.971. בניגוד לכך, בטבלה השלישית אנו מחשבים את האנטרופיה של המחלה, בה 5 אנשים חלו, ו-5 אנשים לא. מצב כזה (שבו לכל תוצאה יש אותה הסתברות) מביא אותנו לאנטרופיה המקסימלית (במקרה הזה 1).

**אנטרופיה מותנית**

אנטרופיה מותנית ([Conditional Entropy](http://en.wikipedia.org/wiki/Conditional_entropy)) היא מדד לאי ודאות של Y בהינתן X, ז”א אנו משתמשים במשתנה אחר (X) על מנת לצמצם את אי הודאות שיש לנו במשתנה Y. לדוגמה, אם אנו רוצים למדוד האם הפעולה הנוכחית בכרטיס אשראי היא חוקית או לא, אנו יכולים להיעזר במיקום הפעולה הקודמת של הלקוח כדי לקבוע האם הפעולה הנוכחית היא חוקית או לא. האנטרופיה המותנית מוגדרת כ- `(H(Y/X) = -∑p(x,y)*logp(y/x`. כאשר (p(x,y היא הסתברות משותפת (ההסתברות ששתי אירועים יקרו ביחד. לדוגמה גם שהתוצאה של הבדיקה תצא שלילית וגם שלבן אדם אין מחלה), ו (p(y/x היא הסתברות מותנת (ההסתברות שיקרה אירוע y, בהינתן x. לדוגמה ההסתברות להיות חולה בהינתן תוצאה שלילית).

חשוב לציין כי לא ניתן לעלות את אי הודאות, ז”א שאם, לדוגמה, אנו רוצים לחזות את ממוצע הציונים של סטודנט באונ’, ומספקים לנו נתון של מידת הנעלים של הסטודנט, די ברור שמידת הנעלים לא קשורה לציון הממוצע של הסטודנט באונ’. אך נתון זה לא יעלה את אי הודאות (רוב הסיכויים שהיא תישאר אותו הדבר). במצב שאין השפעה של המשתנה (קיימת אי תלות בין המשתנים), האנטרופיה המותנית שווה ל-0 (שווה לאנטרופיה של Y).

בתמונה משמאל ניתן לראות דוגמה לאנטרופיה מותנית. השתמשנו באותם נתונים מהדוגמה הקודמת (הטבלה הראשונה זהה), בטבלה השניה אנו מחשבים את ההסתברות המשותפת, בטבלה השלישית את ההסתברות המותנת (ליד כל תוצאה יש הסבר כיצד היא חושבה), ובטבלה הרביעית אנו מחשבים את האנטרופיה המותנית (המשוואה כולה), ומקבלים את התוצאה 0.875.

לעומת זאת אם היינו מחשבים את ההסתברות המותנת של הבדיקה בהינתן המחלה (ולא כפי שעשינו מקודם, בתמונה משמאל), הטבלה הראשונה והשניה היו נשארות זהות, אך בטבלה השלישית והרביעית הינו מקבלים ערכים שונים. בסופו של דבר במקום 0.875 (כתוצאה סופית) היינו מקבלים 0.846. כשהתוצאה גבוהה יותר זה אומר שהגורם שבחרנו כגרום מסביר משפיע פחות על המשתנה התלוי.

בכריית מידע אנו בוחרים באיזשהו משתנה תלוי (שאנו רוצים לחזות אותו) ולאחר מכן אנו מנסים למצוא אלגוריתם שיבנה את המודל הטוב ביותר, שיביא למינימום את האנטרופיה המותנית של המשתנה התלוי. אם למשל היינו רוצים, עפ”י הנתונים למעלה לבנות מודל שנותן חיזוי לגבי מחלה של אדם מסוים לפי תוצאות של בדיקה בודדת, ככל שהיינו מקבלים אנטרופיה מותנית נמוכה יותר כך היינו יודעים שהמודל שמצאנו הוא טוב יותר.

**אינפורמציה הדדית**

כמו שאמרנו בסעיף למעלה, ככל שאנו יודעים יותר על המשתנה התלוי כך האנטרופיה של אותו משתנה תפחת. ההפרש בין האנטרופיה הבלתי מותנית (שלרוב גבוהה יותר) לאנטרופיה המותנית מודד את הצמצום באי הודאות של משתנה מסוים (המשתנה התלוי) כתוצאה מהידע שלנו על משתנה נוסף, וההפרש הזה נקרא אינפורמציה הדדית (המכונה לעיתים גם אינפורמציה משותפת או [Mutual Information](http://en.wikipedia.org/wiki/Mutual_information)).

הנוסחה של האינפורמציה ההדדית היא `[(I(X;Y) = H(Y) – H(Y/X) = ∑p(x,y)*log[p(y/x)] / [p(y`. אם שני המשתנים (x ו y) אינם  תלויים אחד בשני נקבל אינפורמציה הדדית ששוה ל-0, לעומת זאת כשהמידע שלנו ב x מעלה את ההסתברות של y נקבל תוצאה גדולה מ-1, וכמובן יכול להיות מצב הפוך בו נקבל תוצאה נמוכה מ-1 (לדוגמה, כאשר בדיקה מורידה את הסיכוי לחלות במחלה כלשהי).

 **אינפורמציה הדדית מותנית**

המטרה של אינפורמציה הדדית מותנית הוא לחשב את הירידה באי ודאות של משתנה כלשהו x כתוצאה מהידע שלנו לגבי משתנה y, כאשר נתון משתנה נוסף, z. הנוסחה של מושג זה מוגדרת כ `{[(I(X;Y/Z) = H(X/Z) – H(X/Y,Z) = ∑p(x,y,z)*log{[p(x,y/z)]/[p(x/z)*p(y/z`. דוגמה לאינפורמציה הדדית מותנית יכולה להיות כאשר x היא איזשהי מחלה, y ו z הן תוצאות של בדיקות רפואיות כלשהן. יש לנו תוצאה של בדיקה אחת, z, ונשאלת השאלה האם בדיקה נוספת, בדיקה y, תעזור לנו, ז”א תוריד את רמת האי ודאות לגבי המחלה.

 &nbsp;

### 6. תקשורת
בחלק זה נדבר על ההקבלה של בעיות מתחום התקשורת ובעיות בתחום כריית המידע, אותן בעיות שבגללן שנון פיתוח את תורת האינפורמציה. המטרה של תקשורת נתונים היא לשחזר ביעד את ההודעה שנבחרה (או נוצרה) בנק’ המוצא, באופן מדויק (או מקרוב). התקשורת מתבצעת באמצעות קידוד המידע, ז”א מיפוי סדרת סימנים לסימני קוד של המחשב. המטרות העקריות של הקידוד הן:

דחיסת המידע (על מנת להקטין את נפחי האחסון ומשאבי התקשורת).
* חסינות מפני רעשים.
* הצפנה.
* תרגום המידע לקוד מחשב.

בעיית דחיסת המידע היא אחת הבעיות העיקריות בתקשורת נתונים. שנון הגיע למסקנה שעל מנת לצמצם את מס’ הספרות הבינאריות הדרושות לקידוד של הודעה אקראית למינימום צריך להשתמש ב (log(pi- (כאשר i היא ההודעה, ו pi הוא ההסתברות של ההודעה i) ביטים על מנת לשדר אותה (נקצה קודים קצרים יותר להודעות הנשלחות בצורה תקופה יותר, ולהפך). כך שהממוצע של הודעה אקראית יהיה `(H(X) = ∑-p(xi)*log p(xi` (שימו לב כי זאת הנוסחה של האנטרופיה), וזהו מס’ הביטים המינימלי הממוצע הדרוש לנו כדי לשדר הודעות אקראיות ממקור המידע ליעד כלשהו.

**העברת מידע בערוץ רועש**

חסינות המידע לרעשים בסביבה מתאפשרת ע”י הוספת מידע יתיר (redundant) המאפשר לבצע שחזור של הההודעה המקורית למרות הרעשים שנלוו אליה. מנגד, הוספת המידע היתיר מאט את קבצ העברת המידע. על מנת להביא לאופטימום את קצב העברת המידע, יש להתאים את כמות המידע היתיר לרעש. באופן דומה, נניח שהתקבל מידע (תצפיות) ממקור רועש. גודל המדגם (מס’ התצפיות) הוא סופי, וברצוננו למצוא פונ’ או מודל שיתאר את התפלגות המידע שממנו נוצרו התצפיות ולא את התצפיות המסוימות שקיבלו.

עבור כל מודל שנבנה, נבחין בין השגיאה על התצפיות שהתקבלו (נקראת שגיאת אימון) לבין השגיאה הממוצעת על כל התצפיות שיכולנו לקבל (שגיאה הכללה). התאמת יתר (over fitting) היא מצב שבו משיגים שגיאת אמון קטנה על חשבון שגיאת הכללה. בהתאמת יתר נפגמת יכולת החיזוי של המודל (המודל ישגה יותר בעת קבלת דוגמאות חדשות מההתפלגות המקורית). ומכאן שיש למצוא את שביל הביניים בין מודל מורכב ומסובך המתאר את המידע הנתון בדיוק רב ביותר, לבין מודל פשוט בעל יכולת הכללה גדולה יותר.

&nbsp;

### 7. הגישות השונות של כריית מידע
ישנן כמה גישות לכריית מידע, כולן מבוססות באופן ישיר על תורת האינפורמציה.

* **גישת אי הוודאות** – ההנחה היא שכריית המידע מצמצמת את אי הוודאות לגבי משתנים מסויימים (משתני מטרה / חזויים). אחת הדרכים לייצג את אי הוודאות היא ע”י האנטרופיה (ז”א לפתח אלגוריתמים המביאים למינימום את האנטרופיה של המשתנה התלוי, או למקסימום את האינפורמציה ההדדית בין המודל למשתנה התלוי). קיימים לא מעט אלגוריתמים בכריית מידע המיועדים למזער את האנטרופיה כמו ID3 (לבניית עצי החלטה) או C4.5 (גם הוא לבניית עצי החלטה), IFN (לבניית רשתות אינפו-עמומות), ועוד (בהמשך נרחיב עליהם).
* **דחיסת מידע** – בגישה זו אנו מניחים שמודלים קטנים יותר של כריית מידע מובנים יותר למשתמש, למשל עץ החלטה של 10 קודקודים הינו שימושי ומובן יותר מאשר עץ החלטה של 100 או 200 קודקודים. עפ”י גישה זו, המטרה של כריית מידע היא לדחוס את הנתונים ע”י מציאת מודל מסויים שמייצג את הנתונים (אלגוריתמים של כריית מידע אמורים לבחור בהשערה שיש לה אורך תיאור מנימלי, ז”א לבחור בהשערה (או במודל) המצומצם / קטן יותר – נוסחה קצרה יותר, עץ החלטה עם פחות קודקודים, רשת עם פחות שכבות, וכד’). עקרון זה נקרא גם [MDL](http://en.wikipedia.org/wiki/Minimum_description_length) ומשתמשים בו, למשל, באלגוריתמים המבוססים על [חוק בייס](http://en.wikipedia.org/wiki/Bayes%27_theorem).

עקרון ה MDL מייצג את היחס בין סיבוכיות המודל למס’ השגיאות שהמודל יעשה בנתוני האימון (ככל שהמודל יהיה מורכב יותר, כך הוא יתאים יותר לנתונים ויהיו בו פחות שגיאות, ומנגד יכול להיות שיהיה לנו מודל פשוט מאוד אך שלא יתאים לנתונים ולא יהיה מדוייק).

&nbsp;

### לסיכום
אז דיברנו בכלל על למה לכרות מידע, על הסיבה בגינה אנו מחפשים ידע (תבניות / דפוסים) בבסיסי נתונים. הבנו פחות או יותר מהי כריית מידע, ואת התהליכים שצריך לעבור כדי לבצע את התהליך כולו, כשהחשוב בינהם הוא תהליך ה KDD (תהליך גילוי הידע עצמו – השלב בו אנו מפעלים את האלגורימים על הנתונים הנבחרים). הבנו מהו מחסן נתונים (ואת ההבדל של מושג זה מול מושג ה DBMS). ראינו שלמרות שתחום כריית המידע הינו תחום עצמאי, הוא התפתח כתחום כזה מאמצע שנות ה-90, ומבוסס ברובו על דיסציפלינות אחרות, וותיקות יותר, כשהעקרית בינהם היא תורת האינמפורמציה.

הזכרנו מושגים בסיסיים וחשובים בתורת האינפורמציה והבנו כיצד הם מתקשרים לכריית מידע (במיוחד בהיבט של צמצום אי הודאות). דיברנו בקצרה על כיצד מתבצעת תקשורת דיגיטלית ואת הבעיתיות של רעש בערוץ תקשורת. ולבסוף דיברנו על 2 הגישות העקריות והשונות בכריית מידע. בפוסט הבא נתחיל להתעמק בתהליכי כריית המידע עצמם.
